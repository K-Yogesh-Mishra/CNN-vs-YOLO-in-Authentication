{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvBSY04jpaXBJjkjyvEqLs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qNc0O61dOo9I","executionInfo":{"status":"ok","timestamp":1715323255601,"user_tz":-330,"elapsed":22402,"user":{"displayName":"Yogesh Mishra","userId":"05892254449794236446"}},"outputId":"3da0cf62-e20c-4101-a61a-aeae8fdb1f5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["  from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import os\n","\n","# This should be replaced with the path to your test.txt file\n","test_file_path = '/content/gdrive/My Drive/YoloV8_2/data/images/train/test.txt'\n","\n","# Read the test.txt file\n","with open(test_file_path, 'r') as file:\n","    image_paths = file.read().splitlines()\n","\n","# Initialize an empty dictionary to hold the ground truth labels\n","ground_truth = {}\n","\n","# Iterate over the image paths\n","for image_path in image_paths:\n","    # Replace the file extension with .txt to get the path to the annotation file\n","    annotation_path = os.path.splitext(image_path)[0] + '.txt'\n","\n","    # Read the annotation file\n","    with open(annotation_path, 'r') as file:\n","        lines = file.read().splitlines()\n","\n","    # Parse the lines in the annotation file\n","    for line in lines:\n","        # Split the line into components\n","        components = line.split()\n","\n","        # Get the class and bounding box\n","        class_ = int(components[0])\n","        bounding_box = list(map(float, components[1:]))\n","\n","        # Add the ground truth label to the dictionary\n","        ground_truth.setdefault(image_path, []).append((class_, bounding_box))\n","\n","# Print the ground truth labels\n","for image_path, labels in ground_truth.items():\n","    print(f\"Image: {image_path}\")\n","    for label in labels:\n","        if label[0] == 0:\n","            label_name = 'Doctor'\n","        elif label[0] == 1:\n","            label_name = 'Nurse'\n","        elif label[0] == 2:\n","            label_name = 'Patient'\n","        else:\n","            label_name = 'Unknown'\n","        print(f\"  Class: {label_name}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hz9dlFfROqN7","executionInfo":{"status":"ok","timestamp":1715327121799,"user_tz":-330,"elapsed":504,"user":{"displayName":"Yogesh Mishra","userId":"05892254449794236446"}},"outputId":"b38c673d-7291-4f91-b646-c1aab007d45d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d1.jpg\n","  Class: Doctor\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d19.jpg\n","  Class: Doctor\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d26.jpg\n","  Class: Doctor\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d11.jpg\n","  Class: Doctor\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d17.jpg\n","  Class: Doctor\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d25.jpg\n","  Class: Doctor\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/n24.jpg\n","  Class: Nurse\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d23.jpg\n","  Class: Doctor\n"]}]},{"cell_type":"code","source":["import re\n","\n","# Open the file\n","with open('/content/gdrive/My Drive/YoloV8_2/data/images/train/result.txt', 'r') as file:\n","    lines = file.readlines()\n","\n","# Initialize an empty dictionary to hold the results\n","results = {}\n","\n","# Iterate over the lines in the file\n","for line in lines:\n","    # If the line contains a path to an image, this is a new prediction\n","    if line.startswith('/content/gdrive/My Drive/YoloV8_2/data/images/train/'):\n","        # Get the image name\n","        image_path = line.strip().split(':')\n","        image_name = line.strip().split('/')[-1]\n","        # Initialize an empty list to hold the predictions for this image\n","        results[image_name] = []\n","    else:\n","        # If the line contains a prediction, extract the class, confidence, and bounding box\n","        match = re.search(r'(\\w+): (\\d+)%\\t\\(left_x:\\s+(\\d+)\\s+top_y:\\s+(\\d+)\\s+width:\\s+(\\d+)\\s+height:\\s+(\\d+)\\)', line)\n","        if match:\n","            # Get the class, confidence, and bounding box\n","            class_name = match.group(1)\n","            confidence = int(match.group(2))\n","            left_x = int(match.group(3))\n","            top_y = int(match.group(4))\n","            width = int(match.group(5))\n","            height = int(match.group(6))\n","\n","            # Normalize the bounding box values\n","            normalized_bbox = [left_x / width, top_y / height, (left_x + width) / width, (top_y + height) / height]\n","\n","            # Add the prediction to the results\n","            results[image_name].append({\n","                'class': class_name,\n","                'confidence': confidence,\n","                'bounding_box': normalized_bbox\n","            })\n","\n","# Print the results\n","for image_name, predictions in results.items():\n","    print(f\"Image: {image_path[0]}\")\n","    for prediction in predictions:\n","        print(f\"  Class: {prediction['class']}, Confidence: {prediction['confidence']}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_-7OAFEOuuK","executionInfo":{"status":"ok","timestamp":1715324568537,"user_tz":-330,"elapsed":3,"user":{"displayName":"Yogesh Mishra","userId":"05892254449794236446"}},"outputId":"c7c39dac-866c-433f-fe54-e6d339b29822"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d23.jpg\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d23.jpg\n","  Class: nurse, Confidence: 45\n","  Class: doctor, Confidence: 32\n","  Class: doctor, Confidence: 49\n","  Class: nurse, Confidence: 44\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d23.jpg\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d23.jpg\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d23.jpg\n","  Class: doctor, Confidence: 35\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d23.jpg\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d23.jpg\n","  Class: patient, Confidence: 45\n","  Class: nurse, Confidence: 90\n","Image: /content/gdrive/My Drive/YoloV8_2/data/images/train/d23.jpg\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0mDqHgVKQtb4"},"execution_count":null,"outputs":[]}]}